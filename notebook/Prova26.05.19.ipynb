{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/igorecarvalho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /home/igorecarvalho/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importação das bibliotecas criadas para normalização dos dados\n",
    "from nlputils import lexical\n",
    "from nlputils import morphosyntax\n",
    "from nlputils import syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamada da bibioteca de preprocessamento\n",
    "lexical_normalizer = lexical.Preprocessing()\n",
    "morphosyntax_normalizer = morphosyntax.Preprocessing('../models/pt_core_news_sm-2.1.0')\n",
    "syntax_normalizer = syntax.Preprocessing('../models/pt_core_news_sm-2.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#definição do diretorio dos corpus e criacao de uma lista com os nomes de cada arquivo dentro do diretorio\n",
    "corpora_path = '../data/corpora/'\n",
    "files_corpora = os.listdir(corpora_path)\n",
    "files_corpora = [d for d in files_corpora if d not in '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n",
      "664\n"
     ]
    }
   ],
   "source": [
    "#criacao de um dicionario que ira armazenar cada corpus em uma chave\n",
    "sentences_dic = {}\n",
    "all_files = []\n",
    "for corpus in files_corpora:\n",
    "    files = [os.path.join(corpora_path + corpus, f) \\\n",
    "             for f in os.listdir(corpora_path + corpus) \\\n",
    "             if os.path.isfile(os.path.join(corpora_path + corpus, f))]\n",
    "    #cada corpus tera mais 4 chaves para armazenar informacoes de trabalho. Obs.: svo = sujeito, verbo, objeto\n",
    "    sentences_dic[corpus] = {'sentencas': [], 'tag': [], 'parse': [], 'svo': []}\n",
    "    \n",
    "    #adiciona todos os arquivos em uma unica lista independentemente do corpus\n",
    "    print(len(files))\n",
    "    all_files.extend(files)\n",
    "    \n",
    "    #para cada arquivo em um corpus sera extraido suas frases e armazenadas em cada linha de uma lista\n",
    "    for file in files[:30]:\n",
    "        with open(file, 'r', encoding='utf-8') as text_file:\n",
    "            lines = text_file.readlines()\n",
    "            for line in lines:\n",
    "                if line != '\\n':\n",
    "                    #toda a sentenca sera escrita em letras minusculas\n",
    "                    #line = lexical_normalizer.lowercase(line) \n",
    "                    #tokeniza as sentencas\n",
    "                    sentences_line = lexical_normalizer.tokenize_sentences(line)\n",
    "                    for sentence in sentences_line:\n",
    "                        #print(sentence)\n",
    "                        #adiciona cada sentenca de uma linha no dicionario\n",
    "                        sentences_dic[corpus]['sentencas'].append(sentence)\n",
    "                        #adiciona uma lista de cada palavra da sentenca taggeada composta de \n",
    "                        #(token, etiqueta_morfossintática)\n",
    "                        sentences_dic[corpus]['tag'].append(morphosyntax_normalizer.tag(sentence))\n",
    "                        #adiciona uma lista de cada palavra da sentenca composta de \n",
    "                        #(token, papel_sintático, head),\n",
    "                        sentences_dic[corpus]['parse'].append(syntax_normalizer.parse(sentence))\n",
    "                        #adiciona uma lista de cada sentenca composta por tuplas de (sujeito, verbo, objeto)\n",
    "                        sentences_dic[corpus]['svo'].append(syntax_normalizer.get_SVO(sentence))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['animais', 'games'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizacao do Pandas para visualizao dos dados em forma de tabelas\n",
    "import pandas as pd\n",
    "\n",
    "#cracao de um dicionario que ira armazenar cada corpus em suas respectivas keys.\n",
    "dataframes_sentences = {}\n",
    "for key in sentences_dic.keys():\n",
    "    #os corpus armazenados aqui estara em formato de DataFrame onde cada key sera uma coluna da tabela\n",
    "    dataframes_sentences[key] = pd.DataFrame(sentences_dic[key], columns=['sentencas','tag','parse', 'svo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencas</th>\n",
       "      <th>tag</th>\n",
       "      <th>parse</th>\n",
       "      <th>svo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dizem que fomos criados para amar e sermos ama...</td>\n",
       "      <td>[(Dizem, VERB), (que, SCONJ), (fomos, ADJ), (c...</td>\n",
       "      <td>[(Dizem, ROOT, Dizem), (que, mark, criados), (...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por isso, quando nos privam do amor ou da opor...</td>\n",
       "      <td>[(Por, ADP), (isso, PRON), (,, PUNCT), (quando...</td>\n",
       "      <td>[(Por, case, isso), (isso, obl, sentir), (,, p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Este foi o caso de Tonka, uma Vombate australi...</td>\n",
       "      <td>[(Este, PRON), (foi, VERB), (o, DET), (caso, N...</td>\n",
       "      <td>[(Este, nsubj, caso), (foi, cop, caso), (o, de...</td>\n",
       "      <td>[(Este, foi, caso), (que, teve, sérios), (Você...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contaremos um pouco sobre este animal.Caracter...</td>\n",
       "      <td>[(Contaremos, VERB), (um, DET), (pouco, DET), ...</td>\n",
       "      <td>[(Contaremos, ROOT, Contaremos), (um, det, pou...</td>\n",
       "      <td>[(Vombate, é, estranho)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Têm a aparência de um urso musculoso de tamanh...</td>\n",
       "      <td>[(Têm, VERB), (a, DET), (aparência, NOUN), (de...</td>\n",
       "      <td>[(Têm, ROOT, Têm), (a, det, aparência), (aparê...</td>\n",
       "      <td>[(que, permitem, grandes)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentencas  \\\n",
       "0  Dizem que fomos criados para amar e sermos ama...   \n",
       "1  Por isso, quando nos privam do amor ou da opor...   \n",
       "2  Este foi o caso de Tonka, uma Vombate australi...   \n",
       "3  Contaremos um pouco sobre este animal.Caracter...   \n",
       "4  Têm a aparência de um urso musculoso de tamanh...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  [(Dizem, VERB), (que, SCONJ), (fomos, ADJ), (c...   \n",
       "1  [(Por, ADP), (isso, PRON), (,, PUNCT), (quando...   \n",
       "2  [(Este, PRON), (foi, VERB), (o, DET), (caso, N...   \n",
       "3  [(Contaremos, VERB), (um, DET), (pouco, DET), ...   \n",
       "4  [(Têm, VERB), (a, DET), (aparência, NOUN), (de...   \n",
       "\n",
       "                                               parse  \\\n",
       "0  [(Dizem, ROOT, Dizem), (que, mark, criados), (...   \n",
       "1  [(Por, case, isso), (isso, obl, sentir), (,, p...   \n",
       "2  [(Este, nsubj, caso), (foi, cop, caso), (o, de...   \n",
       "3  [(Contaremos, ROOT, Contaremos), (um, det, pou...   \n",
       "4  [(Têm, ROOT, Têm), (a, det, aparência), (aparê...   \n",
       "\n",
       "                                                 svo  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [(Este, foi, caso), (que, teve, sérios), (Você...  \n",
       "3                           [(Vombate, é, estranho)]  \n",
       "4                         [(que, permitem, grandes)]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_sentences['animais'].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencas</th>\n",
       "      <th>tag</th>\n",
       "      <th>parse</th>\n",
       "      <th>svo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Historiador carioca que trabalha como Redator ...</td>\n",
       "      <td>[(Historiador, NOUN), (carioca, VERB), (que, P...</td>\n",
       "      <td>[(Historiador, nsubj, há), (carioca, amod, His...</td>\n",
       "      <td>[(Historiador, há, carioca), (que, trabalha, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Já se aventurou mais de uma vez pelo mundo da ...</td>\n",
       "      <td>[(Já, ADV), (se, PRON), (aventurou, VERB), (ma...</td>\n",
       "      <td>[(Já, advmod, aventurou), (se, expl, aventurou...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de escrever sobre todo tipo de coisa pa...</td>\n",
       "      <td>[(Apesar, ADV), (de, ADP), (escrever, VERB), (...</td>\n",
       "      <td>[(Apesar, advmod, tem), (de, mark, escrever), ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Como jogar Clash Royale no PC, o game de carta...</td>\n",
       "      <td>[(Como, ADV), (jogar, VERB), (Clash, PROPN), (...</td>\n",
       "      <td>[(Como, advmod, jogar), (jogar, ROOT, jogar), ...</td>\n",
       "      <td>[(Clash, jogar, game), (Royale, é, jogo)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apesar da exclusividade para plataformas mobil...</td>\n",
       "      <td>[(Apesar, ADV), (da, ADP), (exclusividade, NOU...</td>\n",
       "      <td>[(Apesar, advmod, levar), (da, obl, Apesar), (...</td>\n",
       "      <td>[(truque, levar, da), (processo, é, gratuito)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentencas  \\\n",
       "0  Historiador carioca que trabalha como Redator ...   \n",
       "1  Já se aventurou mais de uma vez pelo mundo da ...   \n",
       "2  Apesar de escrever sobre todo tipo de coisa pa...   \n",
       "3  Como jogar Clash Royale no PC, o game de carta...   \n",
       "4  Apesar da exclusividade para plataformas mobil...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  [(Historiador, NOUN), (carioca, VERB), (que, P...   \n",
       "1  [(Já, ADV), (se, PRON), (aventurou, VERB), (ma...   \n",
       "2  [(Apesar, ADV), (de, ADP), (escrever, VERB), (...   \n",
       "3  [(Como, ADV), (jogar, VERB), (Clash, PROPN), (...   \n",
       "4  [(Apesar, ADV), (da, ADP), (exclusividade, NOU...   \n",
       "\n",
       "                                               parse  \\\n",
       "0  [(Historiador, nsubj, há), (carioca, amod, His...   \n",
       "1  [(Já, advmod, aventurou), (se, expl, aventurou...   \n",
       "2  [(Apesar, advmod, tem), (de, mark, escrever), ...   \n",
       "3  [(Como, advmod, jogar), (jogar, ROOT, jogar), ...   \n",
       "4  [(Apesar, advmod, levar), (da, obl, Apesar), (...   \n",
       "\n",
       "                                                 svo  \n",
       "0  [(Historiador, há, carioca), (que, trabalha, R...  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3          [(Clash, jogar, game), (Royale, é, jogo)]  \n",
       "4     [(truque, levar, da), (processo, é, gratuito)]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_sentences['games'].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Utilizando\t o\t corpora\t compilado\t para\t a\t Prova\t 1, e\t as\t rotinas\t\n",
    "definidas\t na\t questão\t anterior, realizar\t a\t extração\t de\t informações\t no\t formado\t de\t triplas:\t\n",
    "(Sujeito,\tVerbo,\tObjeto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Um\tdicionário\tPython\tdeve\tser\tcriado\tda\tseguinte\tforma:\n",
    "- a. {“verbo lematizado1”: [(Sujeito1, Objeto1), (Sujeito2,\n",
    "None), ..., (Sujeiton, Objeton)],\n",
    "...,\n",
    "“verbo lematizadok”: [(Sujeito1, Objeto1), (Sujeito2,\n",
    "Objeto2), ..., (Sujeitom, Objetom)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario contendo lista de verbos e para cada verbo uma lista de tuplas contendo (Sujeito, Objeto)\n",
    "lemma_verb = {}\n",
    "#lista de tuplas dos verbos que nao possuem sujeito no formato (verbo lematizado, verbo encontrado)\n",
    "no_obj_verb = []\n",
    "for corpus in sentences_dic:\n",
    "    for sentence in sentences_dic[corpus]['svo']:\n",
    "        for svo in sentence:\n",
    "            if svo[1] != None:\n",
    "                verb = svo[1].lemma_\n",
    "                if verb in lemma_verb.keys():\n",
    "                    lemma_verb[verb].append((svo[0], svo[2]))\n",
    "                else:\n",
    "                    lemma_verb[verb] = []\n",
    "                    lemma_verb[verb].append((svo[0], svo[2]))\n",
    "                if svo[2] == None and svo[2] not in no_obj_verb:\n",
    "                    no_obj_verb.append((verb, svo[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - b. Exibir\tas\tseguintes\testatísticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_verbs = {'verbo': [], 'num_svo': []}\n",
    "for verb in lemma_verb:\n",
    "    stat_verbs['verbo'].append(verb)\n",
    "    stat_verbs['num_svo'].append(len(lemma_verb[verb]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - i. Qual\tverbo\ttem\ta\tmaior\tlista\tde\tsujeitos\te\tobjetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stat_verbs, columns=['verbo','num_svo'])\n",
    "df.sort_values(by=\"num_svo\").tail(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ii.Há\talgum\tverbo\tsem\tobjetos?\tMostre\talguns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(no_obj_verb))\n",
    "print(no_obj_verb[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dada\tuma\tpergunta,\tno\tformato “O\tque/quem\tverbo?”\tresponde “O\tque/quem\tverbo\tobjeto”.\n",
    "- Exemplos\tde\tperguntas:\n",
    "Quem\tpintou\tum\tquadro?\n",
    "O\tque\tderrubou\tos\tpreços?\n",
    "- Exemplos\tde\trespostas:\n",
    "Michelangelo\tpintar\tquadros.\n",
    "Notícias\truins\tderrubar\tos\tpreços."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insira seu login: VTINHI\n",
      "‘Olá, ‘VTINHI\n"
     ]
    }
   ],
   "source": [
    "question = input('Faça uma pergunta no formato:  “O que/quem verbo?” ')\n",
    "ext_data = syntax_normalizer.get_SVO(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos_respostas in ext_data:\n",
    "    verbo = pos_respostas[1].lemma_\n",
    "    obj = pos_respostas[2]\n",
    "    for tupla in lemma_verb[verbo]:\n",
    "        if tupla[1] != None and obj.text == tupla[1].text:\n",
    "            suj = tupla[0]\n",
    "            print(str(suj) + ' ' + str(verbo) + ' ' + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
