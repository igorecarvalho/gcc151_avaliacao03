{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/igorecarvalho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /home/igorecarvalho/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importação das bibliotecas criadas para normalização dos dados\n",
    "from nlputils import lexical\n",
    "from nlputils import morphosyntax\n",
    "from nlputils import syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamada da bibioteca de preprocessamento\n",
    "lexical_normalizer = lexical.Preprocessing()\n",
    "morphosyntax_normalizer = morphosyntax.Preprocessing('../models/pt_core_news_sm-2.1.0')\n",
    "syntax_normalizer = syntax.Preprocessing('../models/pt_core_news_sm-2.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#definição do diretorio dos corpus e criacao de uma lista com os nomes de cada arquivo dentro do diretorio\n",
    "trainset_path = '../data/trainset/'\n",
    "files_trainset_path = os.listdir(trainset_path)\n",
    "files_trainset_path = [d for d in files_trainset_path if d not in '.DS_Store']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "#dicionario de comentarios\n",
    "polarity_dic = {'0.0': [], '1.0': [], '2.0': [], '3.0': [], '4.0': [], '5.0': []}\n",
    "probability = 0.8\n",
    "for path in files_trainset_path:\n",
    "    polarity_dirs = os.listdir(trainset_path + path)\n",
    "    for polarity in polarity_dirs:\n",
    "        polarity_dic[polarity] = {'Comentario': [], 'Polaridade': [], 'Set': []}\n",
    "        commentary_files = []\n",
    "        commentary_files = os.listdir(trainset_path + path + '/' + polarity)\n",
    "        for file in commentary_files:\n",
    "            if '.txt' in file:\n",
    "                with open(trainset_path + path + '/' + polarity + '/' + file, 'r', encoding='utf-8') as text_file:\n",
    "                    lines = text_file.readlines()\n",
    "                    if lines != '\\n':\n",
    "                        polarity_dic[polarity]['Comentario'].append(lines)\n",
    "                        #bin_polarity = 1 if float(polarity) > 3.0 else 0  # transform into binary polarity\n",
    "                        #polarity_dic[polarity]['Polaridade'].append(bin_polarity)\n",
    "                        polarity_dic[polarity]['Polaridade'].append(int(polarity))\n",
    "                        polarity_dic[polarity]['Set'].append('treino' if np.random.rand() < probability else 'teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xmltodict\n",
    "\n",
    "#dicionario de comentarios\n",
    "polarity_dic = {'0.0': [], '1.0': [], '2.0': [], '3.0': [], '4.0': [], '5.0': []}\n",
    "#dicionario de estatisticas\n",
    "commentary_dic = {'Comentario': [], 'Polaridade': [], 'Set': [], 'path': []}\n",
    "\n",
    "probability = 0.8\n",
    "\n",
    "for path in files_trainset_path:\n",
    "    polarity_dirs = os.listdir(trainset_path + path)\n",
    "    for polarity in polarity_dirs:        \n",
    "        commentary_files = []\n",
    "        commentary_files = os.listdir(trainset_path + path + '/' + polarity)\n",
    "        for file in commentary_files:\n",
    "            if '.txt' in file:\n",
    "                with open(trainset_path + path + '/' + polarity + '/' + file, 'r', encoding='utf-8') as text_file:\n",
    "                    lines = text_file.readlines()\n",
    "                    if lines != '\\n':\n",
    "                        polarity_dic[polarity].append(lines)\n",
    "                        string = ''\n",
    "                        for line in lines:\n",
    "                            string = string + ' ' + line\n",
    "                        string = string.replace('\\n', '')\n",
    "                        commentary_dic['Comentario'].append(string)\n",
    "                        commentary_dic['path'].append(trainset_path + path + '/' + polarity + '/' + file)\n",
    "                        #bin_polarity = 1 if float(polarity) > 3.0 else 0  # transform into binary polarity\n",
    "                        #commentary_dic['Polaridade'].append(bin_polarity)\n",
    "                        commentary_dic['Polaridade'].append(float(polarity))\n",
    "                        commentary_dic['Set'].append('treino' if np.random.rand() < probability else 'teste')\n",
    "            if float(polarity) < 4.0:\n",
    "                if '.xml' in file:\n",
    "                    with open(trainset_path + path + '/' + polarity + '/' + file) as text_file:\n",
    "                        #print(trainset_path + path + '/' + polarity + '/' + file)\n",
    "                        doc = xmltodict.parse(text_file.read())\n",
    "                        #pros\n",
    "                        string = doc['review']['pros'].replace('\\n', ' ')\n",
    "                        commentary_dic['Comentario'].append(string)\n",
    "                        commentary_dic['path'].append(trainset_path + path + '/' + polarity + '/' + file)\n",
    "                        #bin_polarity = 1 if float(polarity) > 3.0 else 0  # transform into binary polarity\n",
    "                        #commentary_dic['Polaridade'].append(bin_polarity)\n",
    "                        commentary_dic['Polaridade'].append(float(polarity))\n",
    "                        commentary_dic['Set'].append('treino' if np.random.rand() < probability else 'teste')\n",
    "\n",
    "                        #cons\n",
    "                        string = doc['review']['cons'].replace('\\n', ' ')\n",
    "                        commentary_dic['Comentario'].append(string)\n",
    "                        commentary_dic['path'].append(trainset_path + path + '/' + polarity + '/' + file)\n",
    "                        #bin_polarity = 1 if float(polarity) > 3.0 else 0  # transform into binary polarity\n",
    "                        #commentary_dic['Polaridade'].append(bin_polarity)\n",
    "                        commentary_dic['Polaridade'].append(float(polarity))\n",
    "                        commentary_dic['Set'].append('treino' if np.random.rand() < probability else 'teste')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Produto de Ótimo acabamento, e melhor custo benefício no mercado.  O que gostei: Compacta, design moderno  O que não gostei: não possue controle de temperatura automático',\n",
       " 'Design Custo-Benefício',\n",
       " 'Facilidade de Uso Funções e Características Capacidade de Armazenamento Display Qualidade Facilidade de Limpeza']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentary_dic['Comentario'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comentario</th>\n",
       "      <th>Polaridade</th>\n",
       "      <th>Set</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96812</th>\n",
       "      <td>Lindooooo, Maravilhoso.Adorei e pretendo comp...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_1_314631.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96813</th>\n",
       "      <td>preciso de praticar um esporte, mais estou en...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_1_96367.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96814</th>\n",
       "      <td>eu quero ver em contos que  fica o patins em ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_2_141356.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96815</th>\n",
       "      <td>Esse patins é muito lindo e muito mais confor...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>teste</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_2_156962.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96816</th>\n",
       "      <td>ijiiiii uhuuu uhuuuuu uhuuuuuu uhuuuuu uhuuuu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_2_385214.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96817</th>\n",
       "      <td>Foi muito bom porque andar de patins eu perce...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_2_470323.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96818</th>\n",
       "      <td>este produto é muito bom comprem , não irão s...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_3_148122.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96819</th>\n",
       "      <td>o produto e muito bom</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_3_430394.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96820</th>\n",
       "      <td>APARENTA SER UM PRODUTO DE OTIMA QUALIDADE TE...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>teste</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_4_122386.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96821</th>\n",
       "      <td>a mina opinião é que ele é ótimo nunca andei ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treino</td>\n",
       "      <td>../data/trainset/Patins/5.0/minus_4_253127.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comentario  Polaridade     Set  \\\n",
       "96812   Lindooooo, Maravilhoso.Adorei e pretendo comp...         5.0  treino   \n",
       "96813   preciso de praticar um esporte, mais estou en...         5.0  treino   \n",
       "96814   eu quero ver em contos que  fica o patins em ...         5.0  treino   \n",
       "96815   Esse patins é muito lindo e muito mais confor...         5.0   teste   \n",
       "96816   ijiiiii uhuuu uhuuuuu uhuuuuuu uhuuuuu uhuuuu...         5.0  treino   \n",
       "96817   Foi muito bom porque andar de patins eu perce...         5.0  treino   \n",
       "96818   este produto é muito bom comprem , não irão s...         5.0  treino   \n",
       "96819                              o produto e muito bom         5.0  treino   \n",
       "96820   APARENTA SER UM PRODUTO DE OTIMA QUALIDADE TE...         5.0   teste   \n",
       "96821   a mina opinião é que ele é ótimo nunca andei ...         5.0  treino   \n",
       "\n",
       "                                                 path  \n",
       "96812  ../data/trainset/Patins/5.0/minus_1_314631.txt  \n",
       "96813   ../data/trainset/Patins/5.0/minus_1_96367.txt  \n",
       "96814  ../data/trainset/Patins/5.0/minus_2_141356.txt  \n",
       "96815  ../data/trainset/Patins/5.0/minus_2_156962.txt  \n",
       "96816  ../data/trainset/Patins/5.0/minus_2_385214.txt  \n",
       "96817  ../data/trainset/Patins/5.0/minus_2_470323.txt  \n",
       "96818  ../data/trainset/Patins/5.0/minus_3_148122.txt  \n",
       "96819  ../data/trainset/Patins/5.0/minus_3_430394.txt  \n",
       "96820  ../data/trainset/Patins/5.0/minus_4_122386.txt  \n",
       "96821  ../data/trainset/Patins/5.0/minus_4_253127.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "\n",
    "dataframe = pd.DataFrame(data=commentary_dic)\n",
    "dataframe.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario de sentencas\n",
    "polariy_sentences_dic = {'0.0': [], '1.0': [], '2.0': [], '3.0': [], '4.0': [], '5.0': []}\n",
    "for polarity in polarity_dic:\n",
    "    for commentary in polarity_dic[polarity]:\n",
    "        for line in commentary:\n",
    "            line = line.replace('\\n', '')\n",
    "            sentences_line = lexical_normalizer.tokenize_sentences(line)\n",
    "            for sentence in sentences_line:\n",
    "                polariy_sentences_dic[polarity].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o produto é resistente de ótima qualidade e essa marca é muito confiavel o preço é muito bom.',\n",
       " 'O que gostei: ótima marca.',\n",
       " 'otelefone sem fio intelbras é tudo de bom, pois poder ser usado em todos os movimento pela casa sem incomodo']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polariy_sentences_dic['0.0'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_reviews = dataframe[dataframe['Set'] == 'treino']['Comentario'].values.tolist()\n",
    "train_classes = dataframe[dataframe['Set'] == 'treino']['Polaridade'].values.tolist()\n",
    "test_reviews = dataframe[dataframe['Set'] == 'teste']['Comentario'].values.tolist()\n",
    "test_classes = dataframe[dataframe['Set'] == 'teste']['Polaridade'].values.tolist()\n",
    "\n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(train_reviews)\n",
    "X = transformer.transform(train_reviews)\n",
    "X_test = transformer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comentario</th>\n",
       "      <th>Set</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polaridade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7188</td>\n",
       "      <td>7188</td>\n",
       "      <td>7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>8676</td>\n",
       "      <td>8676</td>\n",
       "      <td>8676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>26811</td>\n",
       "      <td>26811</td>\n",
       "      <td>26811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>25778</td>\n",
       "      <td>25778</td>\n",
       "      <td>25778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>26356</td>\n",
       "      <td>26356</td>\n",
       "      <td>26356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Comentario    Set   path\n",
       "Polaridade                          \n",
       "0.0               2013   2013   2013\n",
       "1.0               7188   7188   7188\n",
       "2.0               8676   8676   8676\n",
       "3.0              26811  26811  26811\n",
       "4.0              25778  25778  25778\n",
       "5.0              26356  26356  26356"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "\n",
    "dataframe = pd.DataFrame(data=commentary_dic)\n",
    "dataframe.groupby('Polaridade').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svr = SVR()\n",
    "svr.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_score(test_classes, svr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0,\n",
       "                   class_weight=[{'0.0': 1, '5.0': 100}, {'1.0': 1, '5.0': 100},\n",
       "                                 {'2.0': 1, '5.0': 100}, {'3.0': 1, '5.0': 25},\n",
       "                                 {'4.0': 1, '5.0': 1}, {'4.0': 1, '5.0': 1}],\n",
       "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "                   l1_ratio=None, max_iter=500, multi_class='warn', n_jobs=6,\n",
       "                   penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peso = [{'0.0': 1, '5.0': 100}, {'1.0': 1, '5.0':100 }, {'2.0': 1, '5.0':100}, {'3.0': 1, '5.0':25}, {'4.0': 1, '5.0': 1}, {'4.0': 1, '5.0': 1}]\n",
    "#peso = [{'0.0': 20, '5.0': 1}, {'1.0': 10, '5.0':1 }, {'2.0': 10, '5.0':1}, {'3.0': 5, '5.0':1}, {'4.0': 1, '5.0': 1}, {'4.0': 1, '5.0': 1}]\n",
    "#peso = {'0.0': 10, '1.0': 8, '2.0': 5, '3.0': 5, '4.0': 8, '5.0': 10}\n",
    "classifier_lr = LogisticRegression(class_weight=peso, n_jobs=6,solver='saga', max_iter=500)\n",
    "#classifier_lr = LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "classifier_lr.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809040542639673"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = lexical_normalizer.lowercase(text)\n",
    "    text = lexical_normalizer.remove_punctuation(text)\n",
    "    tokens = lexical_normalizer.tokenize_words(text)\n",
    "    #tokens = [token for token in tokens if token not in english_stopwords]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme lixo\n",
      "  (0, 29081)\t0.7450931534536025\n",
      "  (0, 22088)\t0.6669604131255216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"filme lixo\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier_lr.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
